{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218f7045-b425-4735-85ab-bb5f1ec3922e",
   "metadata": {},
   "source": [
    "# Chain链之深入理解 Runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed58ee20-3961-4b02-85d8-d385572e430c",
   "metadata": {},
   "source": [
    "## 通过下面的代码更好的理解如何通过RunnableParallel操纵数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83f8873a-567c-4a8c-90fb-80e0c8ae3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    " #这个向量数据库有bug\n",
    "# from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "#换一个新的数据库， pip install chromadb\n",
    "from langchain.vectorstores import Chroma \n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "#这里不写chat_models ,直接从langchain_openai里调ChatOpenAI也OK\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\",\"jerry likes jenny\",\"today is a good day\"],\n",
    "    OpenAIEmbeddings(base_url = os.getenv(\"OPENAI_BASE_URL\")),\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d80232a-ec6a-4cd2-9d09-fa6017073250",
   "metadata": {},
   "source": [
    "## 两种不同的方式设置输入项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f0c873-c815-492f-8da8-641cdee75a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Harrison worked at Kensho.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    temperature = 0.5,\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url = os.getenv(\"OPENAI_BASE_URL\")\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "print()\n",
    "\n",
    "# chain = setup_and_retrieval | prompt | model | output_parser\n",
    "\n",
    "chain = (\n",
    "    {\"context\":retriever,\"question\":RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "response = chain.invoke(\"where did harrison work?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c22faef-d78b-42f0-b6a6-2e78605bdedf",
   "metadata": {},
   "source": [
    "## 添加更多的参数，掌握 itemgetter的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cac3592-a394-4154-a431-165cc101634b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哈里森在Kensho工作。\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "template = \"\"\"\n",
    "\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: \n",
    "{question}\n",
    "\n",
    "Answer in the following language:\n",
    "{language}\n",
    "\n",
    "\"\"\"\n",
    "# 这里注意使用中英文模板会有不同的效果，使用英文模板、中文提问会有问题\n",
    "template2 = \"\"\"\n",
    "\n",
    "只根据下列内容回答用户提出的问题:\n",
    "{context}\n",
    "\n",
    "用户提出的问题: \n",
    "{question}\n",
    "\n",
    "用下列语言进行回答:\n",
    "{language}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template2)\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    temperature = 0.5,\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url = os.getenv(\"OPENAI_BASE_URL\")\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "\n",
    "# chain = setup_and_retrieval | prompt | model | output_parser\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "# 注意，这里context的赋值不能直接把retriever放进来，因为现在有两个输入参数，之前可以是因为只有一个输入参数\n",
    "        \"context\":itemgetter(\"question\") | retriever,\n",
    "        \"question\":itemgetter(\"question\"),\n",
    "        \"language\":itemgetter(\"language\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"question\":\"where did harrison work?\",\n",
    "    \"language\":\"中文\"\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acdc5a9-b1a0-43e8-bfd0-810d51e77bc1",
   "metadata": {},
   "source": [
    "## RunnableParallel 可以用于并行处理两个或多个以上的chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "955eb380-9f01-4361-b2c4-bf76c8a8fc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_chain': '泰国的首都是曼谷。', 'second_chain': '泰国是一个以美食闻名的国家，其菜肴以浓郁的香料和丰富的口味而闻名于世。以下是一些泰国的特色美食：\\n\\n1. 泰式绿咖喱（Green Curry）：由青咖喱酱、椰奶、鸡肉或海鲜、蔬菜等组成，辣味浓郁，口感丰富。\\n\\n2. 泰式烤鱼（Grilled Fish）：以新鲜的鱼类（如鳗鱼）为主料，涂抹上泰式香料酱，然后烤至金黄色。味道鲜美，香气扑鼻。\\n\\n3. 冬阴功汤（Tom Yum）：这是一道酸辣汤，通常用虾、鸡肉或蘑菇等作为主要成分，加入柠檬草、青柠、辣椒和香料煮成。汤口鲜美，辣味浓郁。\\n\\n4. 泰式炒河粉（Pad Thai）：这是一道以米粉为主料的传统泰国菜肴，通常加入虾、豆腐、花生和鸡蛋，配以酸甜的酱汁翻炒而成。口感丰富，味道独特。\\n\\n5. 泰式炸春卷（Spring Rolls）：这是一道常见的泰国小吃，由蔬菜、肉类或海鲜等填充物包裹在薄饼皮中，然后炸至金黄色。口感酥脆，味道美味。\\n\\n6. 芒果糯米饭（Mango Sticky Rice）：这是一道以糯米、新鲜芒果和椰奶为主要材料的传统泰国甜点。口感软糯，甜度适中，是夏季的最佳甜点选择。\\n\\n以上只是泰国美食的一小部分，泰国还有许多其他美味的菜肴，如炒粿条（Pad See Ew）、泰式凉拌生菜（Larb）和泰式烤鸡（Gai Yang）等。无论是辣味浓郁的菜肴还是清淡爽口的甜点，泰国的美食一定会让您的味蕾满意。'}\n"
     ]
    }
   ],
   "source": [
    "chain1 = ChatPromptTemplate.from_template(\"告诉我{country}的首都在哪里？\") | model | output_parser\n",
    "chain2 = ChatPromptTemplate.from_template(\"介绍一下{country}的{topic}有哪些？\") | model | output_parser\n",
    "combined_chain = RunnableParallel (first_chain = chain1, second_chain = chain2)\n",
    "response = combined_chain.invoke({\"country\":\"泰国\",\"topic\":\"美食\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bbf1c8-d295-47c8-b3f7-b853987ec2a2",
   "metadata": {},
   "source": [
    "## 理解 RunnablePassthrough的作用和两种用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44694909-d384-4b23-9f29-0668f12359d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passed': {'num': 1}, 'extra': {'num': 1, 'mult': 3}, 'modified': 2}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    passed=RunnablePassthrough(),\n",
    "    extra=RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3),\n",
    "    modified=lambda x: x[\"num\"] + 1,\n",
    ")\n",
    "\n",
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d3cd07-8db3-4171-9e66-880b19334f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chain': {'num': 1, 'mult': 3, 'triple': 9}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable = RunnableParallel(\n",
    "    \n",
    "    chain=RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3).assign(triple =lambda x: x[\"mult\"] * 3),\n",
    "   \n",
    ")\n",
    "\n",
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0ac42b-3e5f-43b4-a16b-d90566600d61",
   "metadata": {},
   "source": [
    "## 了解RunnableLambda的作用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b17918-a0a5-4621-9729-2d4e3f7b55ff",
   "metadata": {},
   "source": [
    "###  RunnableLambda 可以理解为一个对传递参数的函数运算器，允许你放入一个函数对你要传递的参数进行运算，但是注意放入的函数的输入和输出必须只能有一个参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a235f49a-f186-489d-b30c-948a650f1de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='5 + 15 equals 20.')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    temperature = 0.5,\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url = os.getenv(\"OPENAI_BASE_URL\")\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}\")\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"a\": itemgetter(\"first_name\") | RunnableLambda(length_function),\n",
    "        \"b\": {\"text1\": itemgetter(\"first_name\"), \"text2\": itemgetter(\"last_name\")}\n",
    "        | RunnableLambda(multiple_length_function),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "chain.invoke({\"first_name\": \"jerry\", \"last_name\": \"wan\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
