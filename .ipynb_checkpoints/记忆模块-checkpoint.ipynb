{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a38ea29c-657a-4c2a-9fde-ccf2db1e7892",
   "metadata": {},
   "source": [
    "# 如何添加记忆模块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4dfe2f-ab15-46df-b0aa-b2189f651bd7",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory 是一种最简单的memory，对聊天内容不做任何压缩和处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ebace3-835b-4e48-9f2a-9a5732a869fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ''}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99de2527-9f72-4545-901e-7ce61ef8f430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: hi!\\nAI: what's up?\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"what's up?\")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30e7e33-c4f7-4667-b90e-ffb4bfdc1f9a",
   "metadata": {},
   "source": [
    "## 在LLMChain里添加记忆模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb605e8-bccc-4bf2-8db6-1b416afb00b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a nice chatbot having a conversation with a human.\n",
      "\n",
      "Previous conversation:\n",
      "\n",
      "\n",
      "New human question: hi\n",
      "Response:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a nice chatbot having a conversation with a human.\n",
      "\n",
      "Previous conversation:\n",
      "Human: hi\n",
      "AI:  Hello! How are you doing today?\n",
      "\n",
      "New human question: 你最喜欢什么动物?\n",
      "Response:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a nice chatbot having a conversation with a human.\n",
      "\n",
      "Previous conversation:\n",
      "Human: hi\n",
      "AI:  Hello! How are you doing today?\n",
      "Human: 你最喜欢什么动物?\n",
      "AI:  我最喜欢猫咪！它们又可爱又聪明，总是能给人带来快乐。你呢？你最喜欢什么动物？\n",
      "\n",
      "New human question: 那么它最爱吃什么?\n",
      "Response:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': 'Human: hi\\nAI:  Hello! How are you doing today?\\nHuman: 你最喜欢什么动物?\\nAI:  我最喜欢猫咪！它们又可爱又聪明，总是能给人带来快乐。你呢？你最喜欢什么动物？\\nHuman: 那么它最爱吃什么?\\nAI:  猫咪最爱吃鱼肉和鸡肉，但它们也喜欢吃一些猫粮和零食。它们的食量通常不会很大，但它们会经常吃小量的食物。你有宠物吗？它们喜欢吃什么？'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "llm = OpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url = os.getenv(\"OPENAI_BASE_URL\")\n",
    ")\n",
    "\n",
    "# 注意，在模板里，要给聊天记录留下位置，聊天记录是通过注入给模板来实现的\n",
    "\n",
    "template = \"\"\"You are a nice chatbot having a conversation with a human.\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\n",
    "New human question: {question}\n",
    "Response:\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# `memory_key`要和模板里的参数保持一致\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True, \n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "conversation.invoke({\"question\":\"hi\"})\n",
    "conversation.invoke({\"question\":\"你最喜欢什么动物?\"})\n",
    "conversation.invoke({\"question\":\"那么它最爱吃什么?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e521231-46a7-44ee-b255-59298394f148",
   "metadata": {},
   "source": [
    "## 在LCEL 模式下的chain里添加 memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e5f4e6-090d-4e59-909c-7e93987c9b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import os\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url = os.getenv(\"OPENAI_BASE_URL\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b33410-41f7-4b24-88f4-b6ca7d0f4c69",
   "metadata": {},
   "source": [
    "## 注意 return_messages = True是因为我们选择的是聊天模型包装器ChatOpenAI，memory也要对应选择返回的是messages消息体而不是str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036d68fe-46d6-4a0a-89b0-27b91cf9195a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个中国历史专家.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb97bde0-1d8e-4cb7-bc7d-0dce073183ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m chain \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      2\u001b[0m     RunnablePassthrough\u001b[38;5;241m.\u001b[39massign(\n\u001b[0;32m      3\u001b[0m         history\u001b[38;5;241m=\u001b[39mRunnableLambda(memory\u001b[38;5;241m.\u001b[39mload_memory_variables) \u001b[38;5;241m|\u001b[39m itemgetter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;241m|\u001b[39m llm\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mhistory\u001b[49m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m中国改革开放的总设计师是谁?\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     12\u001b[0m response \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "\n",
    "input = {\"input\":\"中国改革开放的总设计师是谁?\"}\n",
    "response = chain.invoke(input)\n",
    "print(response)\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a03cbb1e-e2a5-4e56-b6ee-242746ebd250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory.save_context(input, {\"output\": response.content})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed6400ba-a6a6-402b-b398-7176056d27c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='很抱歉，我无法回答你的问题，因为你没有提供具体的人物信息。如果你能提供人物的姓名和背景，我将尽力为你提供相关的信息。'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {\"input\":\"他是什么时候去世的?\"}\n",
    "response = chain.invoke(input)\n",
    "print(response)\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f79cf242-e982-46e4-b348-e633c19b9d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='他是什么时候去世的?'),\n",
       "  AIMessage(content='很抱歉，我无法回答你的问题，因为你没有提供具体的人物信息。如果你能提供人物的姓名和背景，我将尽力为你提供相关的信息。')]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context(input, {\"output\": response.content})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
